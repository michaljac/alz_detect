# Model Training Configuration
# Machine learning model configuration for Alzheimer's prediction

# Data configuration
input_dir: "data/featurized"
target_column: "alzheimers_diagnosis"
exclude_columns:
  - "patient_id"
  - "year"

# Split configuration
test_size: 0.2
val_size: 0.2
random_state: 42
stratify: true

# Feature selection
max_features: 150
variance_threshold: 0.01

# Class imbalance handling
handle_imbalance: "class_weight"  # "class_weight", "smote", "none"

# Model configuration
models:
  - "logistic_regression"
  - "xgboost"

# Hyperparameter tuning
enable_hyperparameter_tuning: true
n_trials: 20  # Number of trials for hyperparameter optimization (reduced for faster training)

# XGBoost parameters (these are the actual parameters used)
xgb_params:
  n_estimators: 100
  max_depth: 6
  learning_rate: 0.1
  subsample: 0.8
  colsample_bytree: 0.8
  random_state: 42
  eval_metric: "logloss"

# Logistic Regression parameters
lr_params:
  random_state: 42
  max_iter: 1000

# Output configuration
output_dir: "models"
save_metadata: true

# Wandb configuration
wandb_project: "alz_detect"
wandb_entity: null
log_artifacts: true
